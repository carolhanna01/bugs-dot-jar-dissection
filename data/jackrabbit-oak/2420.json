{"files": 1, "singleLine": false, "nb_error": 1, "failing_tests": ["queryWhileDocsAreRemoved(org.apache.jackrabbit.oak.plugins.document.VersionGCDeletionTest): org.apache.jackrabbit.oak.plugins.document.DocumentStoreException: Error occurred while fetching children for path /node"], "nb_test": 2009, "patch": "diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java\nindex 03dd859..fe60e13 100644\n--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java\n+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java\n@@ -18,6 +18,7 @@ package org.apache.jackrabbit.oak.plugins.document;\n \n import static com.google.common.base.Preconditions.checkArgument;\n import static com.google.common.base.Preconditions.checkNotNull;\n+import static com.google.common.collect.Iterables.filter;\n import static com.google.common.collect.Iterables.toArray;\n import static com.google.common.collect.Iterables.transform;\n import static org.apache.jackrabbit.oak.api.CommitFailedException.MERGE;\n@@ -27,6 +28,7 @@ import static org.apache.jackrabbit.oak.plugins.document.DocumentMK.FAST_DIFF;\n import static org.apache.jackrabbit.oak.plugins.document.DocumentMK.MANY_CHILDREN_THRESHOLD;\n import static org.apache.jackrabbit.oak.plugins.document.UpdateOp.Key;\n import static org.apache.jackrabbit.oak.plugins.document.UpdateOp.Operation;\n+import static org.apache.jackrabbit.oak.plugins.document.util.Utils.getIdFromPath;\n import static org.apache.jackrabbit.oak.plugins.document.util.Utils.unshareString;\n \n import java.io.Closeable;\n@@ -60,6 +62,7 @@ import javax.annotation.Nullable;\n import javax.management.NotCompliantMBeanException;\n \n import com.google.common.base.Function;\n+import com.google.common.base.Predicates;\n import com.google.common.cache.Cache;\n import com.google.common.collect.Iterables;\n import com.google.common.collect.Lists;\n@@ -866,11 +869,11 @@ public final class DocumentNodeStore\n      * @return the child documents.\n      */\n     @Nonnull\n-    Iterable<NodeDocument> readChildDocs(@Nonnull final String path,\n-                                         @Nullable String name,\n-                                         int limit) {\n-        String to = Utils.getKeyUpperLimit(checkNotNull(path));\n-        String from;\n+    private Iterable<NodeDocument> readChildDocs(@Nonnull final String path,\n+                                                 @Nullable String name,\n+                                                 final int limit) {\n+        final String to = Utils.getKeyUpperLimit(checkNotNull(path));\n+        final String from;\n         if (name != null) {\n             from = Utils.getIdFromPath(concat(path, name));\n         } else {\n@@ -881,7 +884,7 @@ public final class DocumentNodeStore\n             // or more than 16k child docs are requested\n             return store.query(Collection.NODES, from, to, limit);\n         }\n-        StringValue key = new StringValue(path);\n+        final StringValue key = new StringValue(path);\n         // check cache\n         NodeDocument.Children c = docChildrenCache.getIfPresent(key);\n         if (c == null) {\n@@ -898,10 +901,10 @@ public final class DocumentNodeStore\n             // fetch more and update cache\n             String lastName = c.childNames.get(c.childNames.size() - 1);\n             String lastPath = concat(path, lastName);\n-            from = Utils.getIdFromPath(lastPath);\n+            String low = Utils.getIdFromPath(lastPath);\n             int remainingLimit = limit - c.childNames.size();\n             List<NodeDocument> docs = store.query(Collection.NODES,\n-                    from, to, remainingLimit);\n+                    low, to, remainingLimit);\n             NodeDocument.Children clone = c.clone();\n             for (NodeDocument doc : docs) {\n                 String p = doc.getPath();\n@@ -911,22 +914,36 @@ public final class DocumentNodeStore\n             docChildrenCache.put(key, clone);\n             c = clone;\n         }\n-        Iterable<NodeDocument> it = transform(c.childNames, new Function<String, NodeDocument>() {\n+        Iterable<NodeDocument> head = filter(transform(c.childNames,\n+                new Function<String, NodeDocument>() {\n             @Override\n             public NodeDocument apply(String name) {\n                 String p = concat(path, name);\n                 NodeDocument doc = store.find(Collection.NODES, Utils.getIdFromPath(p));\n                 if (doc == null) {\n-                    docChildrenCache.invalidateAll();\n-                    throw new NullPointerException(\"Document \" + p + \" not found\");\n+                    docChildrenCache.invalidate(key);\n                 }\n                 return doc;\n             }\n-        });\n-        if (c.childNames.size() > limit * 2) {\n-            it = Iterables.limit(it, limit * 2);\n+        }), Predicates.notNull());\n+        Iterable<NodeDocument> it;\n+        if (c.isComplete) {\n+            it = head;\n+        } else {\n+            // OAK-2420: 'head' may have null documents when documents are\n+            // concurrently removed from the store. concat 'tail' to fetch\n+            // more documents if necessary\n+            final String last = getIdFromPath(concat(\n+                    path, c.childNames.get(c.childNames.size() - 1)));\n+            Iterable<NodeDocument> tail = new Iterable<NodeDocument>() {\n+                @Override\n+                public Iterator<NodeDocument> iterator() {\n+                    return store.query(NODES, last, to, limit).iterator();\n+                }\n+            };\n+            it = Iterables.concat(head, tail);\n         }\n-        return it;\n+        return Iterables.limit(it, limit);\n     }\n \n     /**\n", "project": "jackrabbit-oak", "linesAdd": 32, "nb_skipped": 9, "fix_commit": "24cb1908", "nb_failure": 0, "id": "2420", "linesRem": 15}