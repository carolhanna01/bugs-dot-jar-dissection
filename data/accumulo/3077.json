{"files": 4, "singleLine": false, "nb_error": 0, "failing_tests": [], "nb_test": 6, "patch": "diff --git a/server/base/src/main/java/org/apache/accumulo/server/init/Initialize.java b/server/base/src/main/java/org/apache/accumulo/server/init/Initialize.java\nindex 0a681c4..9b952ba 100644\n--- a/server/base/src/main/java/org/apache/accumulo/server/init/Initialize.java\n+++ b/server/base/src/main/java/org/apache/accumulo/server/init/Initialize.java\n@@ -20,6 +20,7 @@ import java.io.FileNotFoundException;\n import java.io.IOException;\n import java.nio.charset.StandardCharsets;\n import java.util.Arrays;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.Locale;\n@@ -31,6 +32,8 @@ import jline.console.ConsoleReader;\n import org.apache.accumulo.core.Constants;\n import org.apache.accumulo.core.cli.Help;\n import org.apache.accumulo.core.client.AccumuloSecurityException;\n+import org.apache.accumulo.core.client.IteratorSetting;\n+import org.apache.accumulo.core.client.IteratorSetting.Column;\n import org.apache.accumulo.core.client.impl.Namespaces;\n import org.apache.accumulo.core.client.impl.thrift.ThriftSecurityException;\n import org.apache.accumulo.core.conf.AccumuloConfiguration;\n@@ -41,6 +44,8 @@ import org.apache.accumulo.core.data.KeyExtent;\n import org.apache.accumulo.core.data.Value;\n import org.apache.accumulo.core.file.FileOperations;\n import org.apache.accumulo.core.file.FileSKVWriter;\n+import org.apache.accumulo.core.iterators.Combiner;\n+import org.apache.accumulo.core.iterators.IteratorUtil.IteratorScope;\n import org.apache.accumulo.core.iterators.user.VersioningIterator;\n import org.apache.accumulo.core.master.state.tables.TableState;\n import org.apache.accumulo.core.master.thrift.MasterGoalState;\n@@ -65,10 +70,12 @@ import org.apache.accumulo.server.constraints.MetadataConstraints;\n import org.apache.accumulo.server.fs.VolumeManager;\n import org.apache.accumulo.server.fs.VolumeManagerImpl;\n import org.apache.accumulo.server.iterators.MetadataBulkLoadFilter;\n+import org.apache.accumulo.server.replication.StatusCombiner;\n import org.apache.accumulo.server.security.AuditedSecurityOperation;\n import org.apache.accumulo.server.security.SystemCredentials;\n import org.apache.accumulo.server.tables.TableManager;\n import org.apache.accumulo.server.tablets.TabletTime;\n+import org.apache.accumulo.server.util.ReplicationTableUtil;\n import org.apache.accumulo.server.util.TablePropUtil;\n import org.apache.accumulo.server.zookeeper.ZooReaderWriter;\n import org.apache.hadoop.conf.Configuration;\n@@ -84,7 +91,7 @@ import com.beust.jcommander.Parameter;\n \n /**\n  * This class is used to setup the directory structure and the root tablet to get an instance started\n- * \n+ *\n  */\n public class Initialize {\n   private static final Logger log = Logger.getLogger(Initialize.class);\n@@ -102,7 +109,7 @@ public class Initialize {\n \n   /**\n    * Sets this class's ZooKeeper reader/writer.\n-   * \n+   *\n    * @param izoo\n    *          reader/writer\n    */\n@@ -112,7 +119,7 @@ public class Initialize {\n \n   /**\n    * Gets this class's ZooKeeper reader/writer.\n-   * \n+   *\n    * @return reader/writer\n    */\n   static IZooReaderWriter getZooReaderWriter() {\n@@ -566,6 +573,23 @@ public class Initialize {\n   protected static void initMetadataConfig() throws IOException {\n     initMetadataConfig(RootTable.ID);\n     initMetadataConfig(MetadataTable.ID);\n+\n+    // ACCUMULO-3077 Set the combiner on accumulo.metadata during init to reduce the likelihood of a race\n+    // condition where a tserver compacts away Status updates because it didn't see the Combiner configured\n+    IteratorSetting setting = new IteratorSetting(9, ReplicationTableUtil.COMBINER_NAME, StatusCombiner.class);\n+    Combiner.setColumns(setting, Collections.singletonList(new Column(MetadataSchema.ReplicationSection.COLF)));\n+    try {\n+      for (IteratorScope scope : IteratorScope.values()) {\n+        String root = String.format(\"%s%s.%s\", Property.TABLE_ITERATOR_PREFIX, scope.name().toLowerCase(), setting.getName());\n+        for (Entry<String,String> prop : setting.getOptions().entrySet()) {\n+          TablePropUtil.setTableProperty(MetadataTable.ID, root + \".opt.\" + prop.getKey(), prop.getValue());\n+        }\n+        TablePropUtil.setTableProperty(MetadataTable.ID, root, setting.getPriority() + \",\" + setting.getIteratorClass());\n+      }\n+    } catch (Exception e) {\n+      log.fatal(\"Error talking to ZooKeeper\", e);\n+      throw new IOException(e);\n+    }\n   }\n \n   private static void setMetadataReplication(int replication, String reason) throws IOException {\ndiff --git a/server/base/src/main/java/org/apache/accumulo/server/util/ReplicationTableUtil.java b/server/base/src/main/java/org/apache/accumulo/server/util/ReplicationTableUtil.java\nindex 2a9774d..ab5ee86 100644\n--- a/server/base/src/main/java/org/apache/accumulo/server/util/ReplicationTableUtil.java\n+++ b/server/base/src/main/java/org/apache/accumulo/server/util/ReplicationTableUtil.java\n@@ -72,7 +72,7 @@ public class ReplicationTableUtil {\n    * For testing purposes only -- should not be called by server code\n    * <p>\n    * Allows mocking of a Writer for testing\n-   * \n+   *\n    * @param creds\n    *          Credentials\n    * @param writer\n@@ -187,7 +187,7 @@ public class ReplicationTableUtil {\n    */\n   public static void updateFiles(Credentials creds, KeyExtent extent, Collection<String> files, Status stat) {\n     if (log.isDebugEnabled()) {\n-      log.debug(\"Updating replication for \" + extent + \" with \" + files + \" using \" + ProtobufUtil.toString(stat));\n+      log.debug(\"Updating replication status for \" + extent + \" with \" + files + \" using \" + ProtobufUtil.toString(stat));\n     }\n     // TODO could use batch writer, would need to handle failure and retry like update does - ACCUMULO-1294\n     if (files.isEmpty()) {\ndiff --git a/server/tserver/src/main/java/org/apache/accumulo/tserver/log/TabletServerLogger.java b/server/tserver/src/main/java/org/apache/accumulo/tserver/log/TabletServerLogger.java\nindex b4f14ec..26e6891 100644\n--- a/server/tserver/src/main/java/org/apache/accumulo/tserver/log/TabletServerLogger.java\n+++ b/server/tserver/src/main/java/org/apache/accumulo/tserver/log/TabletServerLogger.java\n@@ -276,8 +276,8 @@ public class TabletServerLogger {\n                   logs.add(logger.getFileName());\n                 }\n                 Status status = StatusUtil.fileCreated(System.currentTimeMillis());\n-                log.debug(\"Writing \" + ProtobufUtil.toString(status) + \" to replication table for \" + logs);\n-                // Got some new WALs, note this in the replication table\n+                log.debug(\"Writing \" + ProtobufUtil.toString(status) + \" to metadata table for \" + logs);\n+                // Got some new WALs, note this in the metadata table\n                 ReplicationTableUtil.updateFiles(SystemCredentials.get(), commitSession.getExtent(), logs, status);\n               }\n             }\ndiff --git a/server/tserver/src/main/java/org/apache/accumulo/tserver/tablet/DatafileManager.java b/server/tserver/src/main/java/org/apache/accumulo/tserver/tablet/DatafileManager.java\nindex 5b46b7b..78a2ed6 100644\n--- a/server/tserver/src/main/java/org/apache/accumulo/tserver/tablet/DatafileManager.java\n+++ b/server/tserver/src/main/java/org/apache/accumulo/tserver/tablet/DatafileManager.java\n@@ -61,7 +61,7 @@ class DatafileManager {\n   // access to datafilesizes needs to be synchronized: see CompactionRunner#getNumFiles\n   private final Map<FileRef,DataFileValue> datafileSizes = Collections.synchronizedMap(new TreeMap<FileRef,DataFileValue>());\n   private final Tablet tablet;\n-  \n+\n   // ensure we only have one reader/writer of our bulk file notes at at time\n   private final Object bulkFileImportLock = new Object();\n \n@@ -80,7 +80,7 @@ class DatafileManager {\n   private boolean reservationsBlocked = false;\n \n   private final Set<FileRef> majorCompactingFiles = new HashSet<FileRef>();\n-  \n+\n   static void rename(VolumeManager fs, Path src, Path dst) throws IOException {\n     if (!fs.rename(src, dst)) {\n       throw new IOException(\"Rename \" + src + \" to \" + dst + \" returned false \");\n@@ -268,7 +268,7 @@ class DatafileManager {\n             dfv.setTime(bulkTime);\n           }\n         }\n-        \n+\n         tablet.updatePersistedTime(bulkTime, paths, tid);\n       }\n     }\n@@ -424,6 +424,9 @@ class DatafileManager {\n       // This WAL could still be in use by other Tablets *from the same table*, so we can only mark that there is data to replicate,\n       // but it is *not* closed\n       if (replicate) {\n+        if (log.isDebugEnabled()) {\n+          log.debug(\"Recording that data has been ingested into \" + tablet.getExtent() + \" using \" + logFileOnly);\n+        }\n         ReplicationTableUtil.updateFiles(SystemCredentials.get(), tablet.getExtent(), logFileOnly, StatusUtil.openWithUnknownLength());\n       }\n     } finally {\n@@ -434,7 +437,7 @@ class DatafileManager {\n       try {\n         // the purpose of making this update use the new commit session, instead of the old one passed in,\n         // is because the new one will reference the logs used by current memory...\n-        \n+\n         tablet.getTabletServer().minorCompactionFinished(tablet.getTabletMemory().getCommitSession(), newDatafile.toString(), commitSession.getWALogSeq() + 2);\n         break;\n       } catch (IOException e) {\n@@ -449,19 +452,19 @@ class DatafileManager {\n       if (datafileSizes.containsKey(newDatafile)) {\n         log.error(\"Adding file that is already in set \" + newDatafile);\n       }\n-      \n+\n       if (dfv.getNumEntries() > 0) {\n         datafileSizes.put(newDatafile, dfv);\n       }\n-      \n+\n       if (absMergeFile != null) {\n         datafileSizes.remove(absMergeFile);\n       }\n-      \n+\n       unreserveMergingMinorCompactionFile(absMergeFile);\n-      \n+\n       tablet.flushComplete(flushId);\n-      \n+\n       t2 = System.currentTimeMillis();\n     }\n \n@@ -597,9 +600,9 @@ class DatafileManager {\n       return Collections.unmodifiableSet(files);\n     }\n   }\n-  \n+\n   public int getNumFiles() {\n     return datafileSizes.size();\n   }\n \n-}\n\\ No newline at end of file\n+}\n", "project": "accumulo", "linesAdd": 45, "nb_skipped": 0, "fix_commit": "17654199", "nb_failure": 0, "id": "3077", "linesRem": 18}