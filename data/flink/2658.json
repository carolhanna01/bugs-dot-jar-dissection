{"files": 2, "singleLine": false, "nb_error": 2, "failing_tests": ["FlinkTopologyBuilderTest.testFieldsGroupingOnMultipleBoltOutputStreams:73 \u00bb InvalidProgram", "FlinkTopologyBuilderTest.testFieldsGroupingOnMultipleSpoutOutputStreams:61 \u00bb InvalidProgram"], "nb_test": 125, "patch": "diff --git a/flink-contrib/flink-storm-compatibility/flink-storm-compatibility-core/src/main/java/org/apache/flink/stormcompatibility/api/FlinkTopologyBuilder.java b/flink-contrib/flink-storm-compatibility/flink-storm-compatibility-core/src/main/java/org/apache/flink/stormcompatibility/api/FlinkTopologyBuilder.java\nindex a739c23..e4d880f 100644\n--- a/flink-contrib/flink-storm-compatibility/flink-storm-compatibility-core/src/main/java/org/apache/flink/stormcompatibility/api/FlinkTopologyBuilder.java\n+++ b/flink-contrib/flink-storm-compatibility/flink-storm-compatibility-core/src/main/java/org/apache/flink/stormcompatibility/api/FlinkTopologyBuilder.java\n@@ -78,8 +78,8 @@ public class FlinkTopologyBuilder {\n \t */\n \t@SuppressWarnings({\"rawtypes\", \"unchecked\"})\n \tpublic FlinkTopology createTopology() {\n-\t\tfinal StormTopology stormTopolgoy = this.stormBuilder.createTopology();\n-\t\tfinal FlinkTopology env = new FlinkTopology(stormTopolgoy);\n+\t\tfinal StormTopology stormTopology = this.stormBuilder.createTopology();\n+\t\tfinal FlinkTopology env = new FlinkTopology(stormTopology);\n \t\tenv.setParallelism(1);\n \n \t\tfinal HashMap<String, HashMap<String, DataStream>> availableInputs = new HashMap<String, HashMap<String, DataStream>>();\n@@ -121,7 +121,7 @@ public class FlinkTopologyBuilder {\n \t\t\tavailableInputs.put(spoutId, outputStreams);\n \n \t\t\tint dop = 1;\n-\t\t\tfinal ComponentCommon common = stormTopolgoy.get_spouts().get(spoutId).get_common();\n+\t\t\tfinal ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();\n \t\t\tif (common.is_set_parallelism_hint()) {\n \t\t\t\tdop = common.get_parallelism_hint();\n \t\t\t\tsource.setParallelism(dop);\n@@ -155,7 +155,7 @@ public class FlinkTopologyBuilder {\n \t\t\t\tfinal String boltId = bolt.getKey();\n \t\t\t\tfinal IRichBolt userBolt = bolt.getValue();\n \n-\t\t\t\tfinal ComponentCommon common = stormTopolgoy.get_bolts().get(boltId).get_common();\n+\t\t\t\tfinal ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();\n \n \t\t\t\tSet<Entry<GlobalStreamId, Grouping>> unprocessedInputs = unprocessdInputsPerBolt.get(boltId);\n \t\t\t\tif (unprocessedInputs == null) {\n@@ -194,9 +194,17 @@ public class FlinkTopologyBuilder {\n \t\t\t\t\t\t\t\tfinal List<String> fields = grouping.get_fields();\n \t\t\t\t\t\t\t\tif (fields.size() > 0) {\n \t\t\t\t\t\t\t\t\tFlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n-\t\t\t\t\t\t\t\t\tinputStream = inputStream.groupBy(prodDeclarer\n-\t\t\t\t\t\t\t\t\t\t\t.getGroupingFieldIndexes(inputStreamId,\n-\t\t\t\t\t\t\t\t\t\t\t\t\tgrouping.get_fields()));\n+\t\t\t\t\t\t\t\t\tif (producer.size() == 1) {\n+\t\t\t\t\t\t\t\t\t\tinputStream = inputStream.groupBy(prodDeclarer\n+\t\t\t\t\t\t\t\t\t\t\t\t.getGroupingFieldIndexes(inputStreamId,\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\tgrouping.get_fields()));\n+\t\t\t\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t\t\t\tinputStream = inputStream\n+\t\t\t\t\t\t\t\t\t\t\t\t.groupBy(new SplitStreamTypeKeySelector(\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\tprodDeclarer.getGroupingFieldIndexes(\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tinputStreamId,\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tgrouping.get_fields())));\n+\t\t\t\t\t\t\t\t\t}\n \t\t\t\t\t\t\t\t} else {\n \t\t\t\t\t\t\t\t\tinputStream = inputStream.global();\n \t\t\t\t\t\t\t\t}\ndiff --git a/flink-contrib/flink-storm-compatibility/flink-storm-compatibility-core/src/main/java/org/apache/flink/stormcompatibility/api/SplitStreamTypeKeySelector.java b/flink-contrib/flink-storm-compatibility/flink-storm-compatibility-core/src/main/java/org/apache/flink/stormcompatibility/api/SplitStreamTypeKeySelector.java\nnew file mode 100644\nindex 0000000..30227b8\n--- /dev/null\n+++ b/flink-contrib/flink-storm-compatibility/flink-storm-compatibility-core/src/main/java/org/apache/flink/stormcompatibility/api/SplitStreamTypeKeySelector.java\n@@ -0,0 +1,47 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.flink.stormcompatibility.api;\n+\n+import org.apache.flink.api.java.functions.KeySelector;\n+import org.apache.flink.api.java.tuple.Tuple;\n+import org.apache.flink.stormcompatibility.util.SplitStreamType;\n+import org.apache.flink.streaming.util.keys.KeySelectorUtil;\n+import org.apache.flink.streaming.util.keys.KeySelectorUtil.ArrayKeySelector;\n+\n+/**\n+ * {@link SplitStreamTypeKeySelector} is a specific grouping key selector for streams that are selected via\n+ * {@link FlinkStormStreamSelector} from a Spout or Bolt that declares multiple output streams.\n+ * \n+ * It extracts the wrapped {@link Tuple} type from the {@link SplitStreamType} tuples and applies a regular\n+ * {@link ArrayKeySelector} on it.\n+ */\n+public class SplitStreamTypeKeySelector implements KeySelector<SplitStreamType<Tuple>, Tuple> {\n+\tprivate static final long serialVersionUID = 4672434660037669254L;\n+\n+\tprivate final ArrayKeySelector<Tuple> selector;\n+\n+\tpublic SplitStreamTypeKeySelector(int... fields) {\n+\t\tthis.selector = new KeySelectorUtil.ArrayKeySelector<Tuple>(fields);\n+\t}\n+\n+\t@Override\n+\tpublic Tuple getKey(SplitStreamType<Tuple> value) throws Exception {\n+\t\treturn selector.getKey(value.value);\n+\t}\n+\n+}\n", "project": "flink", "linesAdd": 62, "nb_skipped": 0, "fix_commit": "ce68cbd9", "nb_failure": 0, "id": "2658", "linesRem": 7}