{
  "project": "flink",
  "jira_id": "24282",
  "commit": "724fb3d8",
  "classification": {
    "singleLine": false
  },
  "patch": "diff --git a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaRecordSerializationSchemaBuilder.java b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaRecordSerializationSchemaBuilder.java\nindex 30ff2f8de38..e2d0d2962cb 100644\n--- a/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaRecordSerializationSchemaBuilder.java\n+++ b/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/sink/KafkaRecordSerializationSchemaBuilder.java\n@@ -20,16 +20,14 @@ package org.apache.flink.connector.kafka.sink;\n import org.apache.flink.api.common.serialization.SerializationSchema;\n import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;\n \n-import org.apache.flink.shaded.guava30.com.google.common.cache.CacheBuilder;\n-import org.apache.flink.shaded.guava30.com.google.common.cache.CacheLoader;\n-import org.apache.flink.shaded.guava30.com.google.common.cache.LoadingCache;\n-\n import org.apache.kafka.clients.producer.ProducerRecord;\n import org.apache.kafka.common.Configurable;\n import org.apache.kafka.common.serialization.Serializer;\n \n import javax.annotation.Nullable;\n \n+import java.io.Serializable;\n+import java.util.HashMap;\n import java.util.Map;\n import java.util.OptionalInt;\n import java.util.function.Function;\n@@ -119,7 +117,7 @@ public class KafkaRecordSerializationSchemaBuilder<IN> {\n      * @return {@code this}\n      */\n     public <T extends IN> KafkaRecordSerializationSchemaBuilder<T> setTopicSelector(\n-            Function<? super T, String> topicSelector) {\n+            TopicSelector<? super T> topicSelector) {\n         checkState(this.topicSelector == null, \"Topic selector already set.\");\n         KafkaRecordSerializationSchemaBuilder<T> self = self();\n         self.topicSelector = new CachingTopicSelector<>(checkNotNull(topicSelector));\n@@ -252,34 +250,25 @@ public class KafkaRecordSerializationSchemaBuilder<IN> {\n         checkState(keySerializationSchema == null, \"Key serializer already set.\");\n     }\n \n-    private static class CachingTopicSelector<IN> implements Function<IN, String> {\n+    private static class CachingTopicSelector<IN> implements Function<IN, String>, Serializable {\n \n-        private final LoadingCache<IN, String> cache;\n+        private static final int CACHE_RESET_SIZE = 5;\n+        private final Map<IN, String> cache;\n+        private final TopicSelector<IN> topicSelector;\n \n-        CachingTopicSelector(Function<IN, String> topicSelector) {\n-            this.cache =\n-                    CacheBuilder.newBuilder()\n-                            .maximumSize(5)\n-                            .build(new TopicSelectorCacheLoader<>(topicSelector));\n+        CachingTopicSelector(TopicSelector<IN> topicSelector) {\n+            this.topicSelector = topicSelector;\n+            this.cache = new HashMap<>();\n         }\n \n         @Override\n         public String apply(IN in) {\n-            return cache.getUnchecked(in);\n-        }\n-    }\n-\n-    private static class TopicSelectorCacheLoader<IN> extends CacheLoader<IN, String> {\n-\n-        private final Function<IN, String> topicSelector;\n-\n-        TopicSelectorCacheLoader(Function<IN, String> topicSelector) {\n-            this.topicSelector = topicSelector;\n+            final String topic = cache.getOrDefault(in, topicSelector.apply(in));\n+            cache.put(in, topic);\n+            if (cache.size() == CACHE_RESET_SIZE) {\n+                cache.clear();\n             }\n-\n-        @Override\n-        public String load(IN in) throws Exception {\n-            return topicSelector.apply(in);\n+            return topic;\n         }\n     }\n \n",
  "files": 1,
  "linesAdd": 15,
  "linesRem": 26,
  "failing_tests": [],
  "nb_test": 0,
  "nb_failure": 0,
  "nb_error": 0,
  "nb_skipped": 0
}